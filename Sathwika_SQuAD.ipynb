{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c64c54b-d8c4-4a47-b925-f2ff86d24a1c",
   "metadata": {
    "id": "9c64c54b-d8c4-4a47-b925-f2ff86d24a1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c680ee8c-7787-4519-a65d-c14b7d6be7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from transformers import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef57afcd-b15f-4233-8abd-7c0bd3538957",
   "metadata": {
    "id": "ef57afcd-b15f-4233-8abd-7c0bd3538957"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "MegguFCgzH9s",
   "metadata": {
    "id": "MegguFCgzH9s"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import DistilBertForQuestionAnswering, DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aU6UWuZG60Y-",
   "metadata": {
    "id": "aU6UWuZG60Y-"
   },
   "outputs": [],
   "source": [
    "bs = 8\n",
    "epochs = 3\n",
    "lr = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tZdbkbKQ5X7C",
   "metadata": {
    "id": "tZdbkbKQ5X7C"
   },
   "outputs": [],
   "source": [
    "class SQuAD_Data(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.context_list = []\n",
    "        self.question_list = []\n",
    "        self.answer_list = []\n",
    "        self.start_pos_list = []\n",
    "        self.end_pos_list = []\n",
    "        with open(file_path, 'r', encoding='cp1252') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            for row in reader:\n",
    "                self.context_list.append(row[0])\n",
    "                self.question_list.append(row[1])\n",
    "                self.answer_list.append(row[2])\n",
    "                self.start_pos_list.append(int(row[3]))\n",
    "                self.end_pos_list.append(int(row[4]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.context_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'context': self.context_list[idx],\n",
    "            'question': self.question_list[idx],\n",
    "            'answer': self.answer_list[idx],\n",
    "            'start_pos': self.start_pos_list[idx],\n",
    "            'end_pos': self.end_pos_list[idx]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1269b23b-da52-43a8-850b-403a321f97c0",
   "metadata": {
    "id": "1269b23b-da52-43a8-850b-403a321f97c0",
    "outputId": "61aee01f-9225-439e-8471-7cbb359b9e3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 37079\n",
      "Training loader size: 4635\n",
      "Testing dataset size: 5351\n",
      "Testing loader size: 669\n"
     ]
    }
   ],
   "source": [
    "train_ds = SQuAD_Data('squad_train_data.csv')\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "ds_size = len(train_ds)\n",
    "dl_size = len(train_dl)\n",
    "print(f'Training dataset size: {ds_size}')\n",
    "print(f'Training loader size: {dl_size}')\n",
    "\n",
    "test_ds = SQuAD_Data('squad_test_data.csv')\n",
    "test_dl = DataLoader(test_ds, batch_size=bs, shuffle=True)\n",
    "ds_test_size = len(test_ds)\n",
    "dl_test_size = len(test_dl)\n",
    "print(f'Testing dataset size: {ds_test_size}')\n",
    "print(f'Testing loader size: {dl_test_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "UmLrhnqr9L52",
   "metadata": {
    "id": "UmLrhnqr9L52"
   },
   "outputs": [],
   "source": [
    "def train_fn(train_model, data_ld, optim, device, acc_steps):\n",
    "    train_model.train()\n",
    "    train_model.to(device)\n",
    "    t_loss = 0\n",
    "    scaler_object = GradScaler() \n",
    "    batch_count = 0\n",
    "    for data in data_ld:\n",
    "        inputs = tokenizer(\n",
    "            data['context'],\n",
    "            data['question'],\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            stride=128,\n",
    "            max_length=512\n",
    "        )\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        start_pos = data['start_pos'].to(device)\n",
    "        end_pos = data['end_pos'].to(device)\n",
    "        optim.zero_grad()\n",
    "        with autocast(): \n",
    "            outputs = train_model(**inputs, start_positions=start_pos, end_positions=end_pos)\n",
    "            loss = outputs.loss\n",
    "        scaler_object.scale(loss).backward()\n",
    "        batch_count += 1\n",
    "        if batch_count % acc_steps == 0:\n",
    "            scaler_object.step(optim)  \n",
    "            scaler_object.update()  \n",
    "            optim.zero_grad()   \n",
    "        loss_val = loss.item()\n",
    "        if str(loss_val) == 'nan':\n",
    "            loss_val = 0\n",
    "        t_loss += loss_val\n",
    "    if batch_count % acc_steps != 0:\n",
    "        scaler_object.step(optim)  \n",
    "        scaler_object.update() \n",
    "        optim.zero_grad() \n",
    "    return t_loss / len(data_ld)\n",
    "\n",
    "\n",
    "def test_fn(test_model, data_ld, optim, device):    \n",
    "    t_loss = 0.0\n",
    "    test_model.eval()\n",
    "    test_model.to(device)\n",
    "    scaler_object = GradScaler() \n",
    "    for data in data_ld:\n",
    "        inputs = tokenizer(\n",
    "            data['context'],\n",
    "            data['question'],\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            stride=128,\n",
    "            max_length=512\n",
    "        )\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        start_pos = data['start_pos'].to(device)\n",
    "        end_pos = data['end_pos'].to(device)\n",
    "        optim.zero_grad()\n",
    "        with autocast():  \n",
    "            outputs = test_model(**inputs, start_positions=start_pos, end_positions=end_pos)\n",
    "            loss = outputs.loss\n",
    "        loss_val = loss.item()\n",
    "        if str(loss_val) == 'nan':\n",
    "            loss_val = 0\n",
    "        t_loss += loss_val\n",
    "    return t_loss / len(data_ld)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f24e85e4-3efe-478e-b307-493364ff48b7",
   "metadata": {
    "id": "f24e85e4-3efe-478e-b307-493364ff48b7",
    "outputId": "ca45944b-f4a7-4786-9ced-f094997e0a92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch 1 , train loss 5.6710381880402565, test loss 5.692981338500976\n",
      "Epoch 2 , train loss 5.431648567318916, test loss 5.71663028717041\n",
      "Epoch 3 , train loss 5.215241692960262, test loss 5.727792015075684\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', max_length=512)\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "model = model.to(device)\n",
    "for epoch in range(epochs):\n",
    "    training_loss = train_fn(model, train_dl, optimizer, device, acc_steps=2)\n",
    "    testing_loss = test_fn(model, test_dl, optimizer, device)\n",
    "    print(f'Epoch {epoch+1} , train loss {training_loss}, test loss {testing_loss}')\n",
    "    scheduler.step(testing_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4d7fda2-1eff-4d24-9740-60177854f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting_answer(model, tokenizer, ctx, ques):\n",
    "    inputs = tokenizer(ques, ctx, return_tensors='pt', padding=True, truncation=True)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    input_ids = inputs['input_ids'].squeeze()\n",
    "    output = model(**inputs)\n",
    "    start_index = torch.argmax(output.start_logits)\n",
    "    end_index = torch.argmax(output.end_logits) + 1\n",
    "    if end_index < start_index:\n",
    "        start_index, end_index = end_index, start_index\n",
    "    predicted_answer = tokenizer.decode(input_ids[start_index:end_index])\n",
    "    return predicted_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6909a416-735e-42d0-8aee-ec99fd42e005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american football conference\n"
     ]
    }
   ],
   "source": [
    "para = \"super bowl fifty was an american football game to determine the champion of the national football league nfl for the twenty fifteen season. the american football conference a f c c champion denver broncos defeated the national football conference n f c c champion carolina panthers twenty four to ten to earn their third super bowl title. the game was played on february seventh twenty sixteen and levis stadium in the san francisco bay area santa clara california. as this was the fiftieth super bowl the league emphasized the golden anniversary with various goldsteins initiatives as well as temporarily suspending the tradition of naming each super bowl game with roman numerals under which they gain would have been known as super bowl l sell that the logo could prominently featured the arabic numerals fifty.\"\n",
    "ques = \"What does AFC stand for?\"\n",
    "predicted_answer = predicting_answer(model, tokenizer, para, ques)\n",
    "print(predicted_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21de52c7-f513-4074-a01c-4a836ea33244",
   "metadata": {
    "id": "21de52c7-f513-4074-a01c-4a836ea33244",
    "outputId": "aba95ade-42a0-4f4f-8bfd-10e190dcaa71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 , train loss 5.75785543769598, test loss 5.828500843048095\n",
      "Epoch 2 , train loss 5.645928509533405, test loss 5.828914890289306\n",
      "Epoch 3 , train loss 5.3587766364216805, test loss 5.79552303314209\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased', max_length=512)\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-cased')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "model = model.to(device)\n",
    "for epoch in range(epochs):\n",
    "    training_loss = train_fn(model, train_dl, optimizer, device, acc_steps=2)\n",
    "    testing_loss = test_fn(model, test_dl, optimizer, device)\n",
    "    print(f'Epoch {epoch+1} , train loss {training_loss}, test loss {testing_loss}')\n",
    "    scheduler.step(testing_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "PT_4jbQv7bvY",
   "metadata": {
    "id": "PT_4jbQv7bvY"
   },
   "outputs": [],
   "source": [
    "def predicting_answer(model, tokenizer, ctx, ques):\n",
    "    inputs = tokenizer(ques, ctx, return_tensors='pt', padding=True, truncation=True)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    input_ids = inputs['input_ids'].squeeze()\n",
    "    output = model(**inputs)\n",
    "    start_index = torch.argmax(output.start_logits)\n",
    "    end_index = torch.argmax(output.end_logits) + 1\n",
    "    if end_index < start_index:\n",
    "        start_index, end_index = end_index, start_index\n",
    "    predicted_answer = tokenizer.decode(input_ids[start_index:end_index])\n",
    "    return predicted_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de09e08e-a379-4d2a-adbe-218a9844173b",
   "metadata": {
    "id": "de09e08e-a379-4d2a-adbe-218a9844173b",
    "outputId": "2b5365c0-5050-4334-a5a1-30c975f7fd47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american football conference\n"
     ]
    }
   ],
   "source": [
    "para = \"super bowl fifty was an american football game to determine the champion of the national football league nfl for the twenty fifteen season. the american football conference a f c c champion denver broncos defeated the national football conference n f c c champion carolina panthers twenty four to ten to earn their third super bowl title. the game was played on february seventh twenty sixteen and levis stadium in the san francisco bay area santa clara california. as this was the fiftieth super bowl the league emphasized the golden anniversary with various goldsteins initiatives as well as temporarily suspending the tradition of naming each super bowl game with roman numerals under which they gain would have been known as super bowl l sell that the logo could prominently featured the arabic numerals fifty.\"\n",
    "ques = \"What does AFC stand for?\"\n",
    "predicted_answer = predicting_answer(model, tokenizer, para, ques)\n",
    "print(predicted_answer)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
